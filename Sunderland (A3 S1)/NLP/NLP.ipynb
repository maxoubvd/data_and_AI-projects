{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwSNTcHBGoUK",
        "outputId": "2760ed20-d93f-49ba-aa6f-0e8443a4feaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "import pandas as pd\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import sent_tokenize\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('text.txt', 'r') as file:\n",
        "  content = file.read()\n",
        "\n",
        "print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZgfMrt7HtRq",
        "outputId": "b6df5abd-e7db-4848-a2bd-566a093996f8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial Intelligence (AI) has rapidly evolved over the past few decades, transforming various industries and aspects of daily life. From healthcare to finance, AI algorithms are being used to analyze vast amounts of data, predict trends, and make informed decisions. Machine learning, a subset of AI, enables computers to learn from data without being explicitly programmed, leading to advancements in areas such as image recognition and natural language processing. However, the development of AI also raises ethical concerns, including issues related to privacy, bias, and job displacement. As AI continues to advance, it is crucial for society to address these challenges and ensure that the technology is used responsibly and ethically. Collaboration between governments, companies, and academia is essential to establish guidelines and regulations that promote the beneficial use of AI. Additionally, education and public awareness about AI are important to help people understand its capabilities and limitations. The potential of AI to solve complex problems and improve quality of life is immense, but it requires careful consideration and ongoing dialogue among stakeholders. By fostering a balanced approach to AI development, we can harness its power to create a better future for all.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = content.lower()"
      ],
      "metadata": {
        "id": "czoVDqvMQI4n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(content)\n",
        "for sentence in sentences:\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4snXWQJOEtr",
        "outputId": "a4be2894-3c48-4b79-bbe8-027e5882fa51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "artificial intelligence (ai) has rapidly evolved over the past few decades, transforming various industries and aspects of daily life.\n",
            "from healthcare to finance, ai algorithms are being used to analyze vast amounts of data, predict trends, and make informed decisions.\n",
            "machine learning, a subset of ai, enables computers to learn from data without being explicitly programmed, leading to advancements in areas such as image recognition and natural language processing.\n",
            "however, the development of ai also raises ethical concerns, including issues related to privacy, bias, and job displacement.\n",
            "as ai continues to advance, it is crucial for society to address these challenges and ensure that the technology is used responsibly and ethically.\n",
            "collaboration between governments, companies, and academia is essential to establish guidelines and regulations that promote the beneficial use of ai.\n",
            "additionally, education and public awareness about ai are important to help people understand its capabilities and limitations.\n",
            "the potential of ai to solve complex problems and improve quality of life is immense, but it requires careful consideration and ongoing dialogue among stakeholders.\n",
            "by fostering a balanced approach to ai development, we can harness its power to create a better future for all.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_sentences = []\n",
        "word_frequencies = Counter()\n",
        "\n",
        "for sentence in sentences:\n",
        "  sentence_no_punct = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "  tokens = word_tokenize(sentence_no_punct)\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "  filtered_sentences.append(filtered_tokens)\n",
        "  word_frequencies.update(filtered_tokens)\n",
        "\n",
        "for filtered_sentence in filtered_sentences:\n",
        "  print(filtered_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xABv6g4gQSMY",
        "outputId": "788b2f92-2195-4544-8502-c4127906752e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['artificial', 'intelligence', 'ai', 'rapidly', 'evolved', 'past', 'decades', 'transforming', 'various', 'industries', 'aspects', 'daily', 'life']\n",
            "['healthcare', 'finance', 'ai', 'algorithms', 'used', 'analyze', 'vast', 'amounts', 'data', 'predict', 'trends', 'make', 'informed', 'decisions']\n",
            "['machine', 'learning', 'subset', 'ai', 'enables', 'computers', 'learn', 'data', 'without', 'explicitly', 'programmed', 'leading', 'advancements', 'areas', 'image', 'recognition', 'natural', 'language', 'processing']\n",
            "['however', 'development', 'ai', 'also', 'raises', 'ethical', 'concerns', 'including', 'issues', 'related', 'privacy', 'bias', 'job', 'displacement']\n",
            "['ai', 'continues', 'advance', 'crucial', 'society', 'address', 'challenges', 'ensure', 'technology', 'used', 'responsibly', 'ethically']\n",
            "['collaboration', 'governments', 'companies', 'academia', 'essential', 'establish', 'guidelines', 'regulations', 'promote', 'beneficial', 'use', 'ai']\n",
            "['additionally', 'education', 'public', 'awareness', 'ai', 'important', 'help', 'people', 'understand', 'capabilities', 'limitations']\n",
            "['potential', 'ai', 'solve', 'complex', 'problems', 'improve', 'quality', 'life', 'immense', 'requires', 'careful', 'consideration', 'ongoing', 'dialogue', 'among', 'stakeholders']\n",
            "['fostering', 'balanced', 'approach', 'ai', 'development', 'harness', 'power', 'create', 'better', 'future']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "for filtered_sentence in filtered_sentences:\n",
        "  for filtered_token in filtered_sentence:\n",
        "    print(f\"Word: {filtered_token}, Lemma: {lemmatizer.lemmatize(filtered_token)}\")\n",
        "    filtered_token  = lemmatizer.lemmatize(filtered_token)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNmH8PrsLc7a",
        "outputId": "7bb46c95-4427-402c-bd5c-91c9f0d4e15b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: artificial, Lemma: artificial\n",
            "Word: intelligence, Lemma: intelligence\n",
            "Word: ai, Lemma: ai\n",
            "Word: rapidly, Lemma: rapidly\n",
            "Word: evolved, Lemma: evolved\n",
            "Word: past, Lemma: past\n",
            "Word: decades, Lemma: decade\n",
            "Word: transforming, Lemma: transforming\n",
            "Word: various, Lemma: various\n",
            "Word: industries, Lemma: industry\n",
            "Word: aspects, Lemma: aspect\n",
            "Word: daily, Lemma: daily\n",
            "Word: life, Lemma: life\n",
            "Word: healthcare, Lemma: healthcare\n",
            "Word: finance, Lemma: finance\n",
            "Word: ai, Lemma: ai\n",
            "Word: algorithms, Lemma: algorithm\n",
            "Word: used, Lemma: used\n",
            "Word: analyze, Lemma: analyze\n",
            "Word: vast, Lemma: vast\n",
            "Word: amounts, Lemma: amount\n",
            "Word: data, Lemma: data\n",
            "Word: predict, Lemma: predict\n",
            "Word: trends, Lemma: trend\n",
            "Word: make, Lemma: make\n",
            "Word: informed, Lemma: informed\n",
            "Word: decisions, Lemma: decision\n",
            "Word: machine, Lemma: machine\n",
            "Word: learning, Lemma: learning\n",
            "Word: subset, Lemma: subset\n",
            "Word: ai, Lemma: ai\n",
            "Word: enables, Lemma: enables\n",
            "Word: computers, Lemma: computer\n",
            "Word: learn, Lemma: learn\n",
            "Word: data, Lemma: data\n",
            "Word: without, Lemma: without\n",
            "Word: explicitly, Lemma: explicitly\n",
            "Word: programmed, Lemma: programmed\n",
            "Word: leading, Lemma: leading\n",
            "Word: advancements, Lemma: advancement\n",
            "Word: areas, Lemma: area\n",
            "Word: image, Lemma: image\n",
            "Word: recognition, Lemma: recognition\n",
            "Word: natural, Lemma: natural\n",
            "Word: language, Lemma: language\n",
            "Word: processing, Lemma: processing\n",
            "Word: however, Lemma: however\n",
            "Word: development, Lemma: development\n",
            "Word: ai, Lemma: ai\n",
            "Word: also, Lemma: also\n",
            "Word: raises, Lemma: raise\n",
            "Word: ethical, Lemma: ethical\n",
            "Word: concerns, Lemma: concern\n",
            "Word: including, Lemma: including\n",
            "Word: issues, Lemma: issue\n",
            "Word: related, Lemma: related\n",
            "Word: privacy, Lemma: privacy\n",
            "Word: bias, Lemma: bias\n",
            "Word: job, Lemma: job\n",
            "Word: displacement, Lemma: displacement\n",
            "Word: ai, Lemma: ai\n",
            "Word: continues, Lemma: continues\n",
            "Word: advance, Lemma: advance\n",
            "Word: crucial, Lemma: crucial\n",
            "Word: society, Lemma: society\n",
            "Word: address, Lemma: address\n",
            "Word: challenges, Lemma: challenge\n",
            "Word: ensure, Lemma: ensure\n",
            "Word: technology, Lemma: technology\n",
            "Word: used, Lemma: used\n",
            "Word: responsibly, Lemma: responsibly\n",
            "Word: ethically, Lemma: ethically\n",
            "Word: collaboration, Lemma: collaboration\n",
            "Word: governments, Lemma: government\n",
            "Word: companies, Lemma: company\n",
            "Word: academia, Lemma: academia\n",
            "Word: essential, Lemma: essential\n",
            "Word: establish, Lemma: establish\n",
            "Word: guidelines, Lemma: guideline\n",
            "Word: regulations, Lemma: regulation\n",
            "Word: promote, Lemma: promote\n",
            "Word: beneficial, Lemma: beneficial\n",
            "Word: use, Lemma: use\n",
            "Word: ai, Lemma: ai\n",
            "Word: additionally, Lemma: additionally\n",
            "Word: education, Lemma: education\n",
            "Word: public, Lemma: public\n",
            "Word: awareness, Lemma: awareness\n",
            "Word: ai, Lemma: ai\n",
            "Word: important, Lemma: important\n",
            "Word: help, Lemma: help\n",
            "Word: people, Lemma: people\n",
            "Word: understand, Lemma: understand\n",
            "Word: capabilities, Lemma: capability\n",
            "Word: limitations, Lemma: limitation\n",
            "Word: potential, Lemma: potential\n",
            "Word: ai, Lemma: ai\n",
            "Word: solve, Lemma: solve\n",
            "Word: complex, Lemma: complex\n",
            "Word: problems, Lemma: problem\n",
            "Word: improve, Lemma: improve\n",
            "Word: quality, Lemma: quality\n",
            "Word: life, Lemma: life\n",
            "Word: immense, Lemma: immense\n",
            "Word: requires, Lemma: requires\n",
            "Word: careful, Lemma: careful\n",
            "Word: consideration, Lemma: consideration\n",
            "Word: ongoing, Lemma: ongoing\n",
            "Word: dialogue, Lemma: dialogue\n",
            "Word: among, Lemma: among\n",
            "Word: stakeholders, Lemma: stakeholder\n",
            "Word: fostering, Lemma: fostering\n",
            "Word: balanced, Lemma: balanced\n",
            "Word: approach, Lemma: approach\n",
            "Word: ai, Lemma: ai\n",
            "Word: development, Lemma: development\n",
            "Word: harness, Lemma: harness\n",
            "Word: power, Lemma: power\n",
            "Word: create, Lemma: create\n",
            "Word: better, Lemma: better\n",
            "Word: future, Lemma: future\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_scores = []\n",
        "for i, sentence in enumerate(filtered_sentences):\n",
        "    if len(sentence) < 30:\n",
        "        score = sum(word_frequencies[word] for word in sentence)\n",
        "        sentence_scores.append((i, score))\n",
        "\n",
        "sentence_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "top_sentences = sentence_scores[:2]\n",
        "summary = '\\n'.join(sentences[i].capitalize() for i, _ in top_sentences)\n",
        "\n",
        "print(\"Summary:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQPuUbLkRYaI",
        "outputId": "a3c30552-8041-4211-c4dd-e723d253f63f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            "Machine learning, a subset of ai, enables computers to learn from data without being explicitly programmed, leading to advancements in areas such as image recognition and natural language processing.\n",
            "The potential of ai to solve complex problems and improve quality of life is immense, but it requires careful consideration and ongoing dialogue among stakeholders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGnawQBwSz6N"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}